HDFS：分布式文件系统，存储数据，提供mapreduce。
YARN：资源调度。
working node : 每个资源、配置相近。
master node ：管理员。二者通过网络通信，将任务分配给working nodes，（最后返回master node）。双向：汇总；单向。pc链接master node。
MasterNode<-->WorkingNode
——————————————
HDFS
NameNode<-->DataNode
NameNode：存储索引；Datanode（working node）：存储信息。NameNode根据数据大小决定是否单独储存在服务器，小可以存在working node。
数据容错性：数据冗余：储存其他节点的数据（备份防丢失，数据恢复迁移过程有滞后；计算完整性）
缺点：不擅长随机文件的查找；读取小文件计算慢，大文件较快
最弱环节：NameNode损坏最严重。

————————
Mapreduce：处理框架，计算范式，需要结合实际开发操作。代码传给数据。Map过程假设独立，假设代码适用于各种节点的同类数据。
JobTracker<-->TaskTracker
————————
并行对于资源的消耗：
并行降低时间会先下降持平再上升（资源调度花费时间）；
节点运行稳定；任务拆分均衡；资源调度耗时明显小于计算时间
————————
shuffle 随机打乱，任务均衡 to map；sort 就近map，to reduce
# 数据存在HDFS的硬盘下，map前要进行读数据，存在io消耗时间；map中存在计算，读入硬盘，reducer读硬盘后再计算，最后输出在写入硬盘。目的：节省内存。降低了计算效率，节省成本。

hadoop不适合
即时计算，spark计算（直接存内存，不存硬盘）
迭代计算，牛顿迭代等。

———MapReduce中key value 对
初始市每一个行操作都有唯一的键和值key value；key可以使用位置信息
map后的 key value中key可能会重复

map输出时sort（partition by key 设置排序key）
reducer 接收不同map数据， 进行shuffle，继续sort

shuffle and sort 计算机研究优化hadoop性能
cat 没有换行符时，需要自定义行的截至位置mycat
 
——————
熟悉hadoop下以fs命令开头的所有命名，对应于单机下的命令
hadoop fs
作业2
修改代码；计算通讯时间；随着核数量的增加，通讯时间如何变化


本机与服务器传输文件：filezila（app）；（命令）linux：rlsync -av 源文件 url；scp

备注:windows putty:IP:39.98.252.239;端口：22；用户名：devel；密码：cufe1949!
liunx、powershell：ssh devel@39.98.252.239 ; enter; 密码
学校linux服务器：https：192.168.113.164；账号cufe；密码dashuju；端口22；只能校内使用


————hadoop 命令
hadoop fs -ls /user/devel
hadoop fs -ls / >hadoop-ls.txt 重定向
hadoop fs -get 路径 重命名 #存到本地
hadoop fs -put 上传到hadoop 
-numReducetasks 指定reducers数目

————
日志： tail -f /var/log/lastlog  s 
hadoop 不支持交互模式，比如vim命令 ；

stdin、stdout 标准输入输出

hadoop streaming 提供了其他语言的借口，基于标准输入输出。
token ：jobid 查询任务的唯一标识

#！ python文件抬头
将文件写道sh文件里，运行sh文件
-D == jobconf
————————
linux 命令
pwd 列出当前路径
wc   wordcount 行数 词数 字节 
cat 打印
cat LICENSE.txt | wc   |管道，将左边输入到右边，相当于单机版本的map reduce
which wc 查看绝对路径

echo $HAVA_HOME、HADOOP_HOME 唤起环境变量
ls bin 查看内置命令
etc 记录hadoop内的配置文件，/hadoop 
include lib haddoop 必要的库
pids 程序的id
sbin 安全维护
share hadoop被其他程序调用的模块
————————
快捷键：ctrl a 行首；ctrl e ；ctrl l 清屏；\换行；ctrl k 后面的剪切；



r:4
w：2
x:1
6:r+w
0664：
6首先创建者ower
6 group
4 其他人
对系统管理员无效，拥有所有权限root



——————
R标准输出cat函数，print带有修饰。

screen -DR lifeng 
防止断线，保存；
ctrl a + c；create 创建
ctrl a + n ;next 切换回去，
ctrl a d  退出 
ctrl a k 杀死shell

————————
路径
$HADOOP_HOME
hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar -input /user/lifeng/asm-LICENSE  -output /user/lifeng/output -mapper "/usr/bin/cat" -reducer "/usr/bin/wc" 

linux:
/home/devel/students/2020210990Renqiang
二手车
总数据:/home/devel/data/used_cars_data.csv
/home/devel/students/2020210990Renqiang/us-used-cars/local-type/sample-5.csv

hadoop:
/user/devel/2020210990Renqiang
input:/user/devel/2020210990Renqiang/stocks.txt
output:/user/devel/2020210990Renqiang/output
二手车
总数据: /user/devel/data/used_cars_data.csv

——————————
与服务器传输数据
上传：scp /path/local_filename username@servername:/path 
下载：scp username@servername:/path/filename /tmp/local_destination
作业：清理9G的数据


——————————
单机处理大数据：
open file
while True:
一行一行处理；
设置buffer（缓存） 读取一定大小的数据，总行；可以存为df
if len(buffer)==0: break  -- 判断停止时间


————————
分布式中
python
print 只能标准输出的时候使用
log 模块，记录想要输出的东西




